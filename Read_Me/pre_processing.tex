\section{Pre Processing}\label{prepros}
Before running Scicopia it is needed to load some data to search on into the databases. To do so it is nessesary to follow an strict order.

\subsection{Load the documents into ArangoDB}
For this step use the arangodoc.py locatet in the scicopia directory. It will store the data from the documents in the documentcollection. The database and collection will be createt if not existing.\\
Run from main directory with 
\begin{verbatim}
python -m scicopia.arangodoc [parameters]
\end{verbatim}
The only must parameter is for the type of the input data\\
There are parsers for bibtex, pubmed, arxiv and grobid data included in the project, but it is possible to add more.\\\\
The other parameters are optional:\\
some need other arguments:\\
$--path$, default=``'': str, path to the document directory\\
$-c$, $--compression$, default=``none'': str, type of compression, supported: gzip, zstd, bzip2\\
--batch, default=1000: int, Batch size of bulk import\\
$-p$, $--parallel$: int, distribute the computation on multiple cores\\
$--cluster$: str, distribute the computation onto a cluster\\
\\
some stay alone:\\
$--pdf$: pdfs with same name in same directory as the documents will be stored in the pdfcollection\\
$-r$, $--recursive$: subdirectories will be parsed\\
$--update$: to update already stored documents (PDFs not included)\\

\subsection{Use Scicopia-tools}
There are a few functions to edit the stored documents in the separate Sicopia-tools project \url{https://github.com/pikatech/Scicopia-tools}. It is recommended to use the same config.json.
\begin{verbatim}
python -m scicopia_tools.arangofetch [parameters]
\end{verbatim}
You must choose the used feature and could use the parallel option like in arangodoc.py.\\
The implemented features are ``clean'', ``auto\_tag'' and ``split''\\
\\
``clean'': removes artefacts like Latexcode, works on the ``abstract'', ``title'', ``author'' and ``fulltext'' attributes. It is recomended to use it first because it changes the abstract where the other features are working on.\\
``auto\_tag'': works on the ``abstract'' to creates a keywordslist\\
``split'': works on the ``abstract'' to creates a list with beginn and end index of sentences. Without this list abstracts will NOT be loaded to Elasticsearch.

\subsection{Load Arango data into Elasticsearch}
In this step the fields defined in the config.json will be copied from ArangoDB to Elasticsearch by using docimport.py from main directory. The database will be created if not existing.
\begin{verbatim}
python -m scicopia.elastic.docimport [parameter]
\end{verbatim}
There is an optional parameter:\\
$-t$, $--recent$, default=0: int, only documents that are more recent than this timestamp will be copied\\
\\
\\
There are a few other features in Scicopia that also need collections in ArangoDB.

\subsection{Autocompletion}
The Autocompletion suggests words to search based on the input of the searchfield and the data used to create the autocompletiondata.\\
To create the autocompltiondata use the ngrams.py from the Scicopia-tools Project, it will use the abstracts of the documents saved in arangoDB.\\
Run from main directory with
\begin{verbatim}
python -m scicopia_tools.compile.ngrams [parameter]
\end{verbatim}
The must parameter is for name of the outputfile.\\
% At the moment only .zst is usable
% it is posible to define a file with path
The other parameters are optional:\\
$-n$, default=2-3: str, the order of the n-grams. use single number x or range x-y\\
$--threshold$, $-t$, default=0: int, a threshold for n-gram frequencies to be kept\\
$--patterns$: use a spaCy matcher to extract bigrams. Can only be used for n $\leq$ 5\\
$--weighting$: re-weight the frequencies by their n-gram lengths\\
\\
To import the data run the suggestions.py from the Scicopia main directory via
\begin{verbatim}
python -m scicopia.elastic.suggestions [parameter]
\end{verbatim}
The only parameter is for the name of the created file.\\
It will be imported to the Elasticsearch index defined in config.py as ``suggestions''.

\subsection{Useradministration}
The Userdata is saved in the Usercollection. If it doesn't exists, an empty one will be created while starting the flask server.

\subsection{Graphfeatures}
For the Graphfeatures it is necessary to create collections with the nodes and edges from the graph and change the code in scicopia/app/graph/customize.py to work with the new attributes, especially color and zpos. Pay attention to the comments. The examples in scicopia/app/graph/customize\_dummy.py use the ``World Graph'' example created by ArangoDB. If the Graphcollections are not defined the features are disabled. If there is a problem to load the graphdata from ArangoDB e.g. because the defined collections don't exist, an errorpage will be shown instead.

\subsection{Citationgraph}
The Citationgraph is a graph created by 
\begin{verbatim}
python -m scicopia.graph.citations
\end{verbatim}
It uses the documents form documentcollection in arangoDB to create a graph using the citing %and cited_by
attribute. The graph can be imported with the documentcollection as nodecollection and ``Citations'' as edgecollection.
% TODO: posibility to change names and have only used nodes in graph